{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collecting responses via Nettskjema API\n",
    "From Finn's github: https://github.com/finn42/PullingNettskjema/blob/main/PullingNettskjema.ipynb\n",
    "\n",
    "The following notebook details how to use the Nettskjema API to retrieve responses collected via these webforms. This example combines informatiom from the existing documentation on this API's structure (https://utv.uio.no/docs/nettskjema/api/), code samples of the python library request, documentation of the r library nettskjemar, and some trial and error.\n",
    "\n",
    "In order to access the Nettskjema API, you need:\n",
    "\n",
    "    1) a token (string key) with editing rights to the form in questions\n",
    "    2) a connection from a suitable IP address (such as on the UIO network)\n",
    "    3) suitable commands for retrieving the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting access to the API\n",
    "In order to access a form through the API, you need to generate an api account for your uio account, generate a unique token with suitable roles for that api account, and grant that api account editing privileges for the form(s) you want to access via the API. This is the link to set up and edit your API account within the nettskjema webinterface: https://nettskjema.no/user/api/index.html\n",
    "\n",
    "First create an API account with a simple name and description, then click on that generated account and generate a token with suitable roles and IP restrictions. Tokens are strings that act as keys so the system knows who is logging into the API and that they have permission to do specific things. If you are only downloading responses via API (instead of setting up and editing forms), your token needs only the roles []READ_SUBMISSIONS and []READ_FORMS. If you leave the default IP address range, you can access the API from computers on the UiO network. This include machines logged into remotely (like through VMware Horizon).\n",
    "\n",
    "When you generate/save the token, the next screen shows you the token string. **COPY AND PASTE THIS INTO A FILE RIGHT AWAY as you will never be able to retrieve it again.** (Though it is easy to just generate another token if needed.) This notebook reads a local directory file called 'nettskjema_token.txt' to get the token string.  \n",
    "\n",
    "Once you have the token with suitable roles, click over to your form (nettskjema). Under the Permissions section in settings tab (Rettigheter) should be a list of nettskjema users who have editing rights on this form. So long as you are in one of those accounts, you can add your api account as: \"*yourapiaccountname*@api\". Note: There should not be spaces in the username when you are pasting it in to grant acess. You can check if the rights have been granted properly by going back to your api account details (under https://nettskjema.no/user/api/index.html) and making sure the form is listed in the Forms table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the rights have been granted, we can use the token to access the API programatically. The API documentation gives examples of curl commands that can be run from the command like or terminal (https://utv.uio.no/docs/nettskjema/api/). Below are examples of performing the same tasks with python's request library. Also available is an r library developed by UiO research group LCBC to pull response data directly into r data formats, *nettskjemar*: https://lcbc-uio.github.io/nettskjemar/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accessing the API via Request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import zipfile\n",
    "import os\n",
    "import base64\n",
    "import time\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Navigate to the directory storing your *nettskjema_token.txt* file and read the API token stored there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " 'CompressedData',\n",
       " 'Concert_API',\n",
       " 'InstOrdData',\n",
       " 'nettskjema_token.txt',\n",
       " 'PullingNettskjema.ipynb']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# os.chdir('M:\\\\finnu\\\\kant\\\\div-ritmo-u1')\n",
    "# os.chdir('M:\\\\research')\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open('nettskjema_token.txt','r')\n",
    "TOKEN = f.read()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up a request session with the token information saved into the authentication settings. This allows us to skip spelling out the token string in this notebook with every API request sent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = requests.Session()\n",
    "session.headers.update({'Authorization': 'Bearer ' + TOKEN})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the token by sending a request to see its expiration date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'{\"expireDate\":\"2024-01-31T12:08:10.000+0100\"}'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confirm the token is working on this IP with the check on expiry date\n",
    "request_url = \"https://nettskjema.no/api/v2/users/admin/tokens/expire-date\"\n",
    "response = session.get(request_url)\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " If the token is broken or wrong or too old, you will get an error message like: \n",
    "\n",
    "`b'{\"statusCode\":400,\"message\":\"Not token authenticated\",\"errors\":null,\"nestedErrors\":null}'`\n",
    "\n",
    "If the token is recognised, the output will be just the expiry date:\n",
    "\n",
    "`b'{\"expireDate\":\"2022-10-18T17:38:29.000+0200\"}'`\n",
    "\n",
    "Note: the 'b' before the response string indicates that the API reponse is transmited in bytes. The format is important to handle when trying to store the collected API response data. The standard function .decode() converts the byte string into something python interpretable. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calling for Form metadata\n",
    "\n",
    "If the token is working, next request information about the form you want to get data from. For this you need the formID number, a unique integer assigned by Nettskjema when the form was created. This is at the end of the form URL (ex: 225781 in https://nettskjema.no/a/225781). The page describing which forms your API account has access to also includes these ID numbers (https://nettskjema.no/user/api/index.html#/user)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic request to retreive metadata gives the description of who has access and editing rights, some history of the form, and the content of the form. The information returned to requests about forms are json files which can easily be converted into python dictionaries. \n",
    "\n",
    "It is possible to delete and edit forms through the API, but this isn't described here. The request url formats for these functions should be deducible from the curl commands listed in the API instructions at https://utv.uio.no/docs/nettskjema/api/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'formId': 284191,\n",
       " 'languageCode': 'en',\n",
       " 'title': 'LIVELab Motion Data',\n",
       " 'deliveryDestination': 'DATABASE',\n",
       " 'formType': 'DEFAULT',\n",
       " 'theme': 'DEFAULT',\n",
       " 'createdBy': {'personId': 616293,\n",
       "  'username': 'danasw@uio.no',\n",
       "  'fullName': 'Dana Swarbrick',\n",
       "  'name': 'Dana Swarbrick',\n",
       "  'type': 'LOCAL'},\n",
       " 'modifiedBy': {'personId': 616293,\n",
       "  'username': 'danasw@uio.no',\n",
       "  'fullName': 'Dana Swarbrick',\n",
       "  'name': 'Dana Swarbrick',\n",
       "  'type': 'LOCAL'},\n",
       " 'createdDate': '2022-09-16T21:09:56.000+0200',\n",
       " 'modifiedDate': '2023-01-31T12:12:47.000+0100',\n",
       " 'respondentGroup': 'ALL',\n",
       " 'editorsContactEmail': 'danasw@uio.no',\n",
       " 'editorsSubmissionEmailType': 'NONE',\n",
       " 'editors': [{'personId': 1927165,\n",
       "   'username': 'danasw@api',\n",
       "   'fullName': 'RITMO',\n",
       "   'name': 'RITMO',\n",
       "   'type': 'API'},\n",
       "  {'personId': 616293,\n",
       "   'username': 'danasw@uio.no',\n",
       "   'fullName': 'Dana Swarbrick',\n",
       "   'name': 'Dana Swarbrick',\n",
       "   'type': 'LOCAL'}],\n",
       " 'collectsPersonalData': True,\n",
       " 'maxSubmissionsPerson': 1,\n",
       " 'retainRespondentAccessAfterDelivery': False,\n",
       " 'clientPostponable': False,\n",
       " 'scoreResultDisplayType': 'NONE',\n",
       " 'personalDataPurposeTypes': ['RESEARCH'],\n",
       " 'sensitivePersonalDataCollected': False,\n",
       " 'codebookActivated': False,\n",
       " 'shouldHideProgressBar': False,\n",
       " 'shouldPreventDataManipulation': False,\n",
       " 'shouldGetRespondentInfoFromPerson': False,\n",
       " 'elements': [{'elementId': 4485520,\n",
       "   'elementType': 'QUESTION',\n",
       "   'sequence': 1,\n",
       "   'questions': [{'questionId': 4870947,\n",
       "     'sequence': 1,\n",
       "     'elementType': 'QUESTION',\n",
       "     'mandatory': False,\n",
       "     'text': 'userID',\n",
       "     'sendAdditionalRecipientEmail': False,\n",
       "     'horizontal': False,\n",
       "     'rangeMarksShown': False,\n",
       "     'published': False,\n",
       "     'useForRedirectToForm': False}]},\n",
       "  {'elementId': 4485523,\n",
       "   'elementType': 'ATTACHMENT',\n",
       "   'sequence': 2,\n",
       "   'questions': [{'questionId': 4870950,\n",
       "     'sequence': 1,\n",
       "     'elementType': 'ATTACHMENT',\n",
       "     'mandatory': False,\n",
       "     'text': 'File',\n",
       "     'sendAdditionalRecipientEmail': False,\n",
       "     'horizontal': False,\n",
       "     'rangeMarksShown': False,\n",
       "     'published': False,\n",
       "     'useForRedirectToForm': False}]}],\n",
       " 'newDesignEnabledSetting': 'ALWAYS',\n",
       " 'open': False,\n",
       " 'possibleToHaveInvitations': False,\n",
       " 'postponable': False,\n",
       " 'includingRefererUrl': False,\n",
       " 'tsdConsentForm': False,\n",
       " 'sendingReceiptToRespondent': True}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example metadata API request with simple form of one question.\n",
    "\n",
    "# equivalent curl command\n",
    "#  $ curl 'https://nettskjema.no/api/v2/forms/225781' -i -X GET -H 'Authorization: Bearer TOKEN'\n",
    "\n",
    "formID = 284191\n",
    "request_url = 'https://nettskjema.no/api/v2/forms/' + str(formID)\n",
    "response = session.get(request_url) # using the request session call which includes the saved API token\n",
    "form_metadata = json.loads(response.content.decode()) # intepret recieved string into a python native datatype\n",
    "form_metadata # show the information output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you do not have access rights to a form, or if you are trying to access the API from an IP address that isn't in the range specified by your token, you get API errors instead, like:\n",
    "\n",
    " `{'statusCode': 403,\n",
    " 'message': 'No access to form with id 225782.',\n",
    " 'errors': None,\n",
    " 'nestedErrors': None}`\n",
    " \n",
    " `{'statusCode': 404,\n",
    " 'message': 'Could not find form with id 22578.',\n",
    " 'errors': None,\n",
    " 'nestedErrors': None}`\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The addition of '/submissions' to the request URL calls instead for metadata on the responses, called \"submissions\" by the API. The returned json file is here converted into a list of dictionaries with standard information about each submission (submission ID, created and modified dates, etc.) as well as all the form responses. \n",
    "\n",
    "Responses are returned in reverse chronological order: the last response is the first submission in the list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "formID = 284191\n",
    "request_url = 'https://nettskjema.no/api/v2/forms/' + str(formID) + '/submissions' \n",
    "response = session.get(request_url) # using the request session call which includes the saved API token\n",
    "sub_metadata = json.loads(response.content.decode()) # intepret received string into a python native datatype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most recent submissions: [{'submissionId': 25559872, 'createdDate': '2023-01-31T06:16:01.000+0100', 'modifiedDate': '2023-01-31T06:16:01.000+0100', 'delivered': True, 'answerTime': 0, 'answers': [{'answerId': 144609621, 'questionId': 4870947, 'textAnswer': 'fceec0b7-268e-13aa-f809-b64a3f98c0b5'}, {'answerId': 144609622, 'questionId': 4870950, 'textAnswer': 'data.zip', 'attachments': [{'answerAttachmentId': 482235, 'fileName': 'data.zip', 'mediaType': 'application/zip', 'size': 65663}]}]}, {'submissionId': 25558280, 'createdDate': '2023-01-30T22:59:01.000+0100', 'modifiedDate': '2023-01-30T22:59:01.000+0100', 'delivered': True, 'answerTime': 0, 'answers': [{'answerId': 144605537, 'questionId': 4870947, 'textAnswer': '17cf4405-791f-088b-39ff-b816f9eab2ce'}, {'answerId': 144605536, 'questionId': 4870950, 'textAnswer': 'data.zip', 'attachments': [{'answerAttachmentId': 482189, 'fileName': 'data.zip', 'mediaType': 'application/zip', 'size': 1129}]}]}]\n"
     ]
    }
   ],
   "source": [
    "# examples of the last two responses received\n",
    "print('Most recent submissions: '+str(sub_metadata[:2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Earliest submissions: [{'submissionId': 23063569, 'createdDate': '2022-09-19T17:48:08.000+0200', 'modifiedDate': '2022-09-19T17:48:08.000+0200', 'delivered': True, 'answerTime': 0, 'answers': [{'answerId': 132329985, 'questionId': 4870947, 'textAnswer': '78b0c8ef-dc6a-ce47-eb2d-987ff1dfa003'}, {'answerId': 132329984, 'questionId': 4870950, 'textAnswer': 'data.zip', 'attachments': [{'answerAttachmentId': 419946, 'fileName': 'data.zip', 'mediaType': 'application/zip', 'size': 62101}]}]}, {'submissionId': 23063525, 'createdDate': '2022-09-19T17:45:26.000+0200', 'modifiedDate': '2022-09-19T17:45:26.000+0200', 'delivered': True, 'answerTime': 0, 'answers': [{'answerId': 132329810, 'questionId': 4870947, 'textAnswer': '75e6dffb-6431-4679-77d4-f7dba9f93445'}, {'answerId': 132329811, 'questionId': 4870950, 'textAnswer': 'data.zip', 'attachments': [{'answerAttachmentId': 419944, 'fileName': 'data.zip', 'mediaType': 'application/zip', 'size': 14514}]}]}]\n"
     ]
    }
   ],
   "source": [
    "# the first two submissions received\n",
    "print('Earliest submissions: ' +str(sub_metadata[-2:])) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible to request subsets of responses, specifically all responses after either a specific submission date or submission ID. Submission IDs increase monotonically, assigned uniquely across all of Nettskjema.no. A conveninent trick when downloading responses from an active survey is to call for only those submissions recieved since the last time the data was downloaded. To call only subsets, the request url gets extended with \"&fromDate=\" or \"&fromSubmissionID=\" with the appropriately formated threshold. \n",
    "\n",
    "It is also possible to download only the submission ID field, instead of the full submission details with the addition of \"?fields=submissionId\". At this time, no other fields can be isolated in this way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submissions since date 2022-09-23T19%3A30%3A00.000%2D0400: 10572\n",
      "Most recent submissions: [{'submissionId': 25559872}, {'submissionId': 25558280}]\n",
      "Earliest submissions after concert start: [{'submissionId': 23172340}, {'submissionId': 23172339}]\n"
     ]
    }
   ],
   "source": [
    "# how to call submissions from after a certain date\n",
    "\n",
    "# curl command template\n",
    "# $ curl 'https://nettskjema.no/api/v2/forms/8432376/submissions?fields=submissionId&fromDate=2021-01-11T13%3A43%3A17.486%2B0100' -i -X GET -H 'Authorization: Bearer TOKEN'\n",
    "\n",
    "#ML Cop: 2021-10-25T08:27:22+01:00 # remembrer URL encoding? : is %3A , + is %2B, - is %2D https://www.w3schools.com/tags/ref_urlencode.ASP\n",
    "#date = '2021-10-25T08%3A27%3A22.000%2B0100'\n",
    "\n",
    "formID = 284191\n",
    "# Audience Experience Study: September 23, 2022 7:30pm. The concert started slightly late so we can safely assume that this captures meaningful motion data\n",
    "# 2022-09-23T19:30:00-04:00 # -4 because summer time is UTC-4h with daylight savings time/summer time\n",
    "# 2022-09-23T19%3A30%3A00.000%2D0400\n",
    "date = '2022-09-23T19%3A30%3A00.000%2D0400'\n",
    "\n",
    "request_url = 'https://nettskjema.no/api/v2/forms/' + str(formID) + '/submissions?fields=submissionId&fromDate=' + date\n",
    "\n",
    "response = session.get(request_url)\n",
    "subIDs = json.loads(response.content.decode())\n",
    "\n",
    "print('Submissions since date ' + date + ': ' + str(len(subIDs)))\n",
    "if len(subIDs)<5:\n",
    "    print(subIDs)\n",
    "else:\n",
    "    print('Most recent submissions: '+ str(subIDs[:2])) # Note: this shows the last 2 submissions, not the first two submissions\n",
    "    print('Earliest submissions after concert start: ' + str(subIDs[-2:])) # Note: these are the first two submissions from concert start. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Forms that do not collect personal information on Nettskjema do not retain dates in a format that can be used for this kind of range restriction. You will get this error when trying to call a subset of responses by date: \n",
    "\n",
    "`{'statusCode': 409, 'message': 'Since the form does not collect personal data, the submissions will not have dates to compare with the fromDate parameter', 'errors': None, 'nestedErrors': None}`\n",
    "\n",
    "In this case, it is necessary to find a suitable submissionID that corresponds to the same temporal threshold. If you are monitoring an active survey, use the ID of the first `[0]` submissionID from your last API call. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submissions since subID 23172339: 10571\n",
      "{'submissionId': 25559872}\n"
     ]
    }
   ],
   "source": [
    "# how to call submissions from after a certain ID, restricting metadata to submission ID\n",
    "# curl command template\"\n",
    "# $ curl 'https://nettskjema.no/api/v2/forms/225781/submissions?fields=submissionId&fromSubmissionId=16653694' -i -X GET \\\n",
    "#   -H 'Authorization: Bearer TOKEN'\n",
    "\n",
    "formID = 284191\n",
    "submissionID = 23172339 # Earliest submission after concert start\n",
    "request_url = 'https://nettskjema.no/api/v2/forms/' + str(formID) + '/submissions?fields=submissionId&fromSubmissionId=' + str(submissionID)\n",
    "response = session.get(request_url)\n",
    "subIDs = json.loads(response.content.decode())\n",
    "print('Submissions since subID ' + str(submissionID) + ': ' + str(len(subIDs)))\n",
    "if len(subIDs)<5: # print error message or top responses \n",
    "    print(subIDs)\n",
    "else:\n",
    "    print(subIDs[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gathering Musiclab phone sensor data\n",
    "The above commands cover access to forms that collect information strickly through the webform interface. Apps like Musiclab also gather information in different shapes that are stored by nettskjema as attachments to submissions (responses). These are a bit trickier to retrieve, but still accessible through the API. \n",
    "\n",
    "Note: the following cells will not run without permissions for the MusicLab form on Nettskjema, but the shape should be the same for any forms that collects attachments with submissions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the difference between the chunk above and below is just the fields=submissionId section in the request url. Above only returns the submission ID and below returns the full submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submissions since subID 23172339: 10571\n",
      "{'submissionId': 25559872, 'createdDate': '2023-01-31T06:16:01.000+0100', 'modifiedDate': '2023-01-31T06:16:01.000+0100', 'delivered': True, 'answerTime': 0, 'answers': [{'answerId': 144609622, 'questionId': 4870950, 'textAnswer': 'data.zip', 'attachments': [{'answerAttachmentId': 482235, 'fileName': 'data.zip', 'mediaType': 'application/zip', 'size': 65663}]}, {'answerId': 144609621, 'questionId': 4870947, 'textAnswer': 'fceec0b7-268e-13aa-f809-b64a3f98c0b5'}]}\n",
      "{'submissionId': 23172340, 'createdDate': '2022-09-24T01:30:02.000+0200', 'modifiedDate': '2022-09-24T01:30:02.000+0200', 'delivered': True, 'answerTime': 0, 'answers': [{'answerId': 132652669, 'questionId': 4870950, 'textAnswer': 'data.zip', 'attachments': [{'answerAttachmentId': 422499, 'fileName': 'data.zip', 'mediaType': 'application/zip', 'size': 295698}]}, {'answerId': 132652670, 'questionId': 4870947, 'textAnswer': '0eceb1a9-9ba3-a39b-2e8e-f32a5887fa40'}]}\n"
     ]
    }
   ],
   "source": [
    "# get metadata on submissions for the music lab app after a certain submission ID\n",
    "\n",
    "formID = 284191\n",
    "submissionID = 23172339 # collect responses from after this submission ID. \n",
    "request_url = 'https://nettskjema.no/api/v2/forms/' + str(formID) + '/submissions?fromSubmissionId=' + str(submissionID)\n",
    "response = session.get(request_url)\n",
    "subIDs = json.loads(response.content.decode())\n",
    "print('Submissions since subID ' + str(submissionID) + ': ' + str(len(subIDs)))\n",
    "if len(subIDs)<5: # print error message or top responses \n",
    "    print(subIDs)\n",
    "else:\n",
    "    print(subIDs[0]) # print the most recent submission\n",
    "    print(subIDs[-1]) # print the earliest submission after the concert start (after response 23172339 which was collected '2022-09-23T19%3A30%3A00.000%2D0400' \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to retrieve the sensor data stored in the submission attachment, we have to call for each file individually and save it appropriately. Here are the essential details from one submission out of the metadata called above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submissionID : 25559872\n",
      "Submitting installation: fceec0b7-268e-13aa-f809-b64a3f98c0b5\n",
      "[{'answerAttachmentId': 482235, 'fileName': 'data.zip', 'mediaType': 'application/zip', 'size': 65663}]\n"
     ]
    }
   ],
   "source": [
    "subn = 0\n",
    "print('submissionID : ' + str(subIDs[subn]['submissionId']))\n",
    "for ans in subIDs[subn]['answers']:\n",
    "    if 'textAnswer' in ans:\n",
    "        if len(ans['textAnswer'])>12:\n",
    "            print('Submitting installation: ' + ans['textAnswer'])\n",
    "    if 'attachments' in ans:\n",
    "        print(ans['attachments'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so to call the attachment for that submission we use the request:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileName: data.zip\n",
      "fileSize: 65663\n",
      "mediaType: application/zip\n",
      "content: UEsDBAoAAAAAANQpP1aVqMo0lf8AAJX/AABEAAAAMjAyMy0wMS0zMVQwNS0xNC00MC4yMDdaX2ZjZWVjMGI3LTI2OGUtMTNhYS1mODA5LWI2NGEzZjk4YzBiNV9kbS5jc3Z0aW1lc3RhbXAsdGltZSx4LHkseixhbHBoYSxiZXRhLGdhbW1hDQoiMjAyMy0wMS0zMVQwNToxNDoyOC44MjlaIiwyNDg1My4yOTk5OTk5ODIxMiwtMS44LDkuMjAwMDAwMDAwMDAwMDAxLDIuOTAwMDAwMDAwMDAwMDAwNCwtMTUuNzAwMDAwMDAwMDAwMDAxLC0xMy4xMDAwMDAwMDAwMDAwMDEsLTQuNA0KIjIwMjMtMDEtMzFUMDU6MTQ6MjguODQ1WiIsMjQ4NzAsLTEuOCw5LjIwMDAwMDAwMDAwMDAwMSwyLjkwMDAwMDAwMDAwMDAwMDQsLTEzLjkwMDAwMDAwMDAwMDAwMiwtMTQsLTMuNjAw...\n"
     ]
    }
   ],
   "source": [
    "subn = 0 # just calling one as an example\n",
    "\n",
    "subID = str(subIDs[subn]['submissionId'])\n",
    "for ans in subIDs[subn]['answers']:\n",
    "    if 'attachments' in ans:\n",
    "        attID = str(ans['attachments'][0]['answerAttachmentId'])\n",
    "request_url = 'https://nettskjema.no/api/v2/submissions/' + subID + '/attachments/' + attID\n",
    "response = session.get(request_url)\n",
    "\n",
    "att_dets = json.loads(response.content.decode())\n",
    "print('fileName: ' + att_dets['fileName'])\n",
    "print('fileSize: ' + str(att_dets['fileSize']))\n",
    "print('mediaType: ' + att_dets['mediaType'])\n",
    "print('content: ' + att_dets['content'][:500] + '...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The nettskjema API returns attachments as 64encoded zipfiles in byte strings. To make these readable, we need to decode then save the string as a zip file and then unzip them. Thankfully there are python libraries for this.  \n",
    "\n",
    "First be sure you are in a suitable local folder, then unpack the attachment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir('./Test_API')\n",
    "os.chdir('Test_API')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Think of \"sub\" as submission (not subject) in the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['25559872', 'data.zip']\n",
      "['2023-01-31T05-14-40.207Z_fceec0b7-268e-13aa-f809-b64a3f98c0b5_dm.csv']\n"
     ]
    }
   ],
   "source": [
    "subn = 0 # just calling the most recent one as an example\n",
    "\n",
    "subID = str(subIDs[subn]['submissionId'])\n",
    "for ans in subIDs[subn]['answers']:\n",
    "    if 'attachments' in ans:\n",
    "        attID = str(ans['attachments'][0]['answerAttachmentId'])\n",
    "request_url = 'https://nettskjema.no/api/v2/submissions/' + subID + '/attachments/' + attID\n",
    "response = session.get(request_url)\n",
    "\n",
    "att_dets = json.loads(response.content.decode())\n",
    "\n",
    "# write the decoded attachment into a zip file\n",
    "f=open('data.zip', 'wb')\n",
    "f.write(base64.b64decode(att_dets['content']))\n",
    "f.close()\n",
    "\n",
    "# and then unzip that file, leaving a uniquely titled csv, I hope\n",
    "with zipfile.ZipFile('data.zip', 'r') as zip_ref:\n",
    "    if not os.path.exists(str(subID)):\n",
    "        os.mkdir(str(subID))\n",
    "        zip_ref.extractall('./'+str(subID)) # Not unique filenames so use the unique submission IDs \n",
    "\n",
    "print(os.listdir())\n",
    "os.chdir('./'+str(subID))\n",
    "print(os.listdir())\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have a minute recording from a device with the unique installation ID 'fceec0b7-268e...' in a format that is easy to read. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The files within the zip are named for the device and information type, but do not include the submission number. They do however contain a datetime string in ISO format which means they are extremely unlikely to be overwritten. To avoid this, the files are unzipped within a folder names for that unique submission. \n",
    "\n",
    "Now to collect many at once: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time to collect 25 attachments: 2.039228916168213\n"
     ]
    }
   ],
   "source": [
    "# pull in attachment files and unpack them\n",
    "\n",
    "checkedSubs = 25\n",
    "\n",
    "newSubs = 0 # count the submission sampled\n",
    "tic = time.time()\n",
    "for submis in subIDs[:checkedSubs]: # just getting 25 as a test\n",
    "    # first find out the attachment file ID for this submission\n",
    "    subID = str(submis['submissionId'])\n",
    "    # if there is an IDed attachment for this submission, get the file\n",
    "    for subm in submis['answers']:\n",
    "        if len(subm)>3: # cheat to pick out only submissions with attachments. might fail.\n",
    "            attID = str(subm['attachments'][0]['answerAttachmentId'])\n",
    "            request_url = 'https://nettskjema.no/api/v2/submissions/' + subID + '/attachments/' + attID\n",
    "            response = session.get(request_url)\n",
    "            newSubs += 1\n",
    "            att_dets = json.loads(response.content.decode())\n",
    "            # write the decoded attachment into a zip file\n",
    "            f=open('data.zip', 'wb')\n",
    "            f.write(base64.b64decode(att_dets['content']))\n",
    "            f.close()\n",
    "            # and then unzip that file, leaving a uniquely titled csv, I hope\n",
    "            with zipfile.ZipFile('data.zip', 'r') as zip_ref:\n",
    "                if not os.path.exists(str(subID)):\n",
    "                    os.mkdir(str(subID))\n",
    "                    zip_ref.extractall('./'+str(subID)) # if not unique can use the unique submission IDs \n",
    "\n",
    "print('time to collect ' + str(newSubs) + ' attachments: ' + str(time.time() - tic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The files can then be crawled for with suitable information about which submissions related to which installations, i.e., what can be sewn together in order. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compressing submission files\n",
    "For some forms of storage and retrieval of unzipped data, this folder-per-submission arrangement is really awkward. The following shows two reorganisation schemes. The first moves the files from a long list of folders to a single folder while adding the submission number to filenames to preserve uniqueness. The second organises the files into unique installation folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('..')\n",
    "#os.mkdir('CompressedData')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['25490506',\n",
       " '25490507',\n",
       " '25490508',\n",
       " '25490509',\n",
       " '25490512',\n",
       " '25490513',\n",
       " '25490514',\n",
       " '25490516',\n",
       " '25490517',\n",
       " '25490518',\n",
       " '25490520',\n",
       " '25490521',\n",
       " '25503764',\n",
       " '25507775',\n",
       " '25516198',\n",
       " '25516199',\n",
       " '25516200',\n",
       " '25516201',\n",
       " '25517587',\n",
       " '25541487',\n",
       " '25541490',\n",
       " '25541503',\n",
       " '25542763',\n",
       " '25558280',\n",
       " '25559872',\n",
       " 'data.zip']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folders = os.listdir('Test_API')\n",
    "folders "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['25490506.2023-01-26T21-47-05.780Z_29692813-c50d-22a3-c078-e9b165eed306_dm.csv',\n",
       " '25490506.2023-01-26T21-47-05.780Z_29692813-c50d-22a3-c078-e9b165eed306_gl.csv',\n",
       " '25490507.2023-01-26T21-47-08.306Z_29692813-c50d-22a3-c078-e9b165eed306_dm.csv',\n",
       " '25490507.2023-01-26T21-47-08.306Z_29692813-c50d-22a3-c078-e9b165eed306_gl.csv',\n",
       " '25490508.2023-01-26T21-47-11.221Z_29692813-c50d-22a3-c078-e9b165eed306_dm.csv',\n",
       " '25490508.2023-01-26T21-47-11.221Z_29692813-c50d-22a3-c078-e9b165eed306_gl.csv',\n",
       " '25490509.2023-01-26T21-47-15.351Z_29692813-c50d-22a3-c078-e9b165eed306_dm.csv',\n",
       " '25490509.2023-01-26T21-47-15.351Z_29692813-c50d-22a3-c078-e9b165eed306_gl.csv',\n",
       " '25490512.2023-01-26T21-47-21.607Z_29692813-c50d-22a3-c078-e9b165eed306_dm.csv',\n",
       " '25490512.2023-01-26T21-47-21.607Z_29692813-c50d-22a3-c078-e9b165eed306_gl.csv',\n",
       " '25490513.2023-01-26T21-47-26.176Z_29692813-c50d-22a3-c078-e9b165eed306_dm.csv',\n",
       " '25490513.2023-01-26T21-47-26.176Z_29692813-c50d-22a3-c078-e9b165eed306_gl.csv',\n",
       " '25490514.2023-01-26T21-47-31.580Z_29692813-c50d-22a3-c078-e9b165eed306_dm.csv',\n",
       " '25490514.2023-01-26T21-47-31.580Z_29692813-c50d-22a3-c078-e9b165eed306_gl.csv',\n",
       " '25490516.2023-01-26T21-47-35.268Z_29692813-c50d-22a3-c078-e9b165eed306_dm.csv',\n",
       " '25490516.2023-01-26T21-47-35.268Z_29692813-c50d-22a3-c078-e9b165eed306_gl.csv',\n",
       " '25490517.2023-01-26T21-47-38.580Z_29692813-c50d-22a3-c078-e9b165eed306_dm.csv',\n",
       " '25490517.2023-01-26T21-47-38.580Z_29692813-c50d-22a3-c078-e9b165eed306_gl.csv',\n",
       " '25490518.2023-01-26T21-47-42.320Z_29692813-c50d-22a3-c078-e9b165eed306_dm.csv',\n",
       " '25490518.2023-01-26T21-47-42.320Z_29692813-c50d-22a3-c078-e9b165eed306_gl.csv',\n",
       " '25490520.2023-01-26T21-47-46.822Z_29692813-c50d-22a3-c078-e9b165eed306_dm.csv',\n",
       " '25490520.2023-01-26T21-47-46.822Z_29692813-c50d-22a3-c078-e9b165eed306_gl.csv',\n",
       " '25490521.2023-01-26T21-47-49.608Z_29692813-c50d-22a3-c078-e9b165eed306_dm.csv',\n",
       " '25490521.2023-01-26T21-47-49.608Z_29692813-c50d-22a3-c078-e9b165eed306_gl.csv',\n",
       " '25503764.2023-01-27T19-10-53.211Z_fa0c30a6-f531-5eab-d1c3-b68407d76d42_dm.csv',\n",
       " '25503764.2023-01-27T19-10-53.211Z_fa0c30a6-f531-5eab-d1c3-b68407d76d42_gl.csv',\n",
       " '25507775.2023-01-27T23-14-08.177Z_ec41dd5d-5162-f6ad-8622-10c936895910_dm.csv',\n",
       " '25507775.2023-01-27T23-14-08.177Z_ec41dd5d-5162-f6ad-8622-10c936895910_gl.csv',\n",
       " '25516198.2023-01-29T01-49-41.086Z_a991cbae-01d5-de82-7eaf-1bda8c6a08d4_dm.csv',\n",
       " '25516199.2023-01-29T01-49-48.663Z_a991cbae-01d5-de82-7eaf-1bda8c6a08d4_dm.csv',\n",
       " '25516200.2023-01-29T01-50-55.644Z_a991cbae-01d5-de82-7eaf-1bda8c6a08d4_dm.csv',\n",
       " '25516201.2023-01-29T01-50-58.108Z_a991cbae-01d5-de82-7eaf-1bda8c6a08d4_dm.csv',\n",
       " '25517587.2023-01-29T11-46-25.328Z_0ca55e4f-7f76-08b0-7aaa-e56d70981de4_dm.csv',\n",
       " '25541487.2023-01-29T22-49-21.801Z_4e53851d-962c-55a9-36eb-388f5cb8a0fa_dm.csv',\n",
       " '25541490.2023-01-29T22-49-36.308Z_4e53851d-962c-55a9-36eb-388f5cb8a0fa_dm.csv',\n",
       " '25541503.2023-01-29T22-50-03.860Z_4e53851d-962c-55a9-36eb-388f5cb8a0fa_dm.csv',\n",
       " '25542763.2023-01-30T11-48-55.452Z_6f4f3465-d7fe-ae8b-717a-31db209e2b51_dm.csv',\n",
       " '25558280.2023-01-30T21-59-00.152Z_17cf4405-791f-088b-39ff-b816f9eab2ce_dm.csv',\n",
       " '25559872.2023-01-31T05-14-40.207Z_fceec0b7-268e-13aa-f809-b64a3f98c0b5_dm.csv']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to put all the files inside the CompressedData folder for fastest sftp transfer (SSH file transfer protocol / secure ftp) \n",
    "for subid in folders:\n",
    "    if subid.startswith('2'):\n",
    "        filenames = os.listdir('./Test_API/'+str(subid))\n",
    "        #print(filenames)\n",
    "        for fn in filenames:\n",
    "            if fn.endswith('.csv'):\n",
    "                sourcefile = './Test_API/'+str(subid) + '/' + fn\n",
    "                targetfile = './CompressedData/'+str(subid) + '.' + fn\n",
    "                #print(targetfile)\n",
    "                shutil.copy2(sourcefile,targetfile)\n",
    "                \n",
    "os.listdir('./CompressedData/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To organise the files into folders per installation, we monitor and generate new folders as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir('InstOrdData') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0ca55e4f-7f76-08b0-7aaa-e56d70981de4',\n",
       " '17cf4405-791f-088b-39ff-b816f9eab2ce',\n",
       " '29692813-c50d-22a3-c078-e9b165eed306',\n",
       " '4e53851d-962c-55a9-36eb-388f5cb8a0fa',\n",
       " '6f4f3465-d7fe-ae8b-717a-31db209e2b51',\n",
       " 'a991cbae-01d5-de82-7eaf-1bda8c6a08d4',\n",
       " 'ec41dd5d-5162-f6ad-8622-10c936895910',\n",
       " 'fa0c30a6-f531-5eab-d1c3-b68407d76d42',\n",
       " 'fceec0b7-268e-13aa-f809-b64a3f98c0b5']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to put all the files inside the Installation Ordered Data folder for fastest sftp transfer\n",
    "foldlist = os.listdir('./InstOrdData/')\n",
    "\n",
    "for subid in folders:\n",
    "    if subid.startswith('2'):\n",
    "        filenames = os.listdir('./Test_API/'+str(subid))\n",
    "        #print(filenames)\n",
    "        for fn in filenames:\n",
    "            if fn.endswith('.csv'):\n",
    "                # extract the installation ID \n",
    "                #subdets = fn.split('.') # worked before but now with the time, this was splitting at the ms level and the ms was being included with the installation ID\n",
    "                subdets = fn.split('_') # splits it into date, installation, type (dm.csv or gl.csv)\n",
    "                instid = subdets[1] # changed from Finn's because Pedro includes the date and time in the submission name!\n",
    "                # if the device doesn't have a folder, generate one\n",
    "                if instid not in foldlist:\n",
    "                    os.mkdir('./InstOrdData/' + instid)\n",
    "                    foldlist = os.listdir('./InstOrdData/')\n",
    "                    \n",
    "                sourcefile = './Test_API/' + str(subid) + '/' + fn\n",
    "                targetfile = './InstOrdData/' + instid + '/'+str(subid) + '.' + fn\n",
    "                #print(targetfile)\n",
    "                shutil.copy2(sourcefile,targetfile)\n",
    "                \n",
    "os.listdir('./InstOrdData/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, if we need to use sftp to move the data, we don't need to crawl through thousands of folders to find it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the LIVELab Concert project, we only want data collected in close temporal proximit to September 23rd 7:30-9:30 p.m. Luckily date is stored in the file name in UTC. createdDate is also storing the time stamp in UTC+2 hence the +0200 at the end (summer time in Oslo).\n",
    "\n",
    "Therefore I need to go through the files and only retrieve the attachments if it contains that date at the beginning of the filename. The concert began at 2022-09-23T19:30:00.000-0400 = 2022-09-24T01:30:00.000+0200\n",
    "\n",
    "In the subIDs list, the first submission is 23172339 with 'createdDate': '2022-09-24T01:30:02.000+0200'\n",
    "\n",
    "The last submission on September 24th was 23187860 with created date: 2022-09-24T21:22:18.000+0200\n",
    "However that is too late for the concert end therefore, the last reasonable time is perhaps 2 hours after concert start and would then be around '2022-09-24T03:30:02.000+0200'\n",
    "\n",
    "This submission corresponds to ID 23181108.\n",
    "\n",
    "Therefore the range in IDs is probably 23172339-23181108.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submissions since date 2022-09-23T19%3A30%3A00.000%2D0400: 10572\n",
      "Most recent submissions: [{'submissionId': 25559872}, {'submissionId': 25558280}]\n",
      "Earliest submissions after concert start: [{'submissionId': 23172340}, {'submissionId': 23172339}]\n"
     ]
    }
   ],
   "source": [
    "formID = 284191\n",
    "# Audience Experience Study: September 23, 2022 7:30pm. The concert started slightly late so we can safely assume that this captures meaningful motion data\n",
    "# 2022-09-23T19:30:00-04:00 # -4 because summer time is UTC-4h with daylight savings time/summer time\n",
    "# 2022-09-23T19%3A30%3A00.000%2D0400\n",
    "date = '2022-09-23T19%3A30%3A00.000%2D0400'\n",
    "\n",
    "request_url = 'https://nettskjema.no/api/v2/forms/' + str(formID) + '/submissions?fromDate=' + date\n",
    "\n",
    "response = session.get(request_url)\n",
    "subIDs = json.loads(response.content.decode())\n",
    "\n",
    "print('Submissions since date ' + date + ': ' + str(len(subIDs)))\n",
    "if len(subIDs)<5:\n",
    "    print(subIDs)\n",
    "else:\n",
    "    print('Most recent submissions: '+ str(subIDs[:2])) # Note: this shows the last 2 submissions, not the first two submissions\n",
    "    print('Earliest submissions after concert start: ' + str(subIDs[-2:])) # Note: these are the first two submissions from concert start. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submissions since subID 23172339: 10571\n",
      "{'submissionId': 25559872, 'createdDate': '2023-01-31T06:16:01.000+0100', 'modifiedDate': '2023-01-31T06:16:01.000+0100', 'delivered': True, 'answerTime': 0, 'answers': [{'answerId': 144609622, 'questionId': 4870950, 'textAnswer': 'data.zip', 'attachments': [{'answerAttachmentId': 482235, 'fileName': 'data.zip', 'mediaType': 'application/zip', 'size': 65663}]}, {'answerId': 144609621, 'questionId': 4870947, 'textAnswer': 'fceec0b7-268e-13aa-f809-b64a3f98c0b5'}]}\n",
      "{'submissionId': 23172340, 'createdDate': '2022-09-24T01:30:02.000+0200', 'modifiedDate': '2022-09-24T01:30:02.000+0200', 'delivered': True, 'answerTime': 0, 'answers': [{'answerId': 132652669, 'questionId': 4870950, 'textAnswer': 'data.zip', 'attachments': [{'answerAttachmentId': 422499, 'fileName': 'data.zip', 'mediaType': 'application/zip', 'size': 295698}]}, {'answerId': 132652670, 'questionId': 4870947, 'textAnswer': '0eceb1a9-9ba3-a39b-2e8e-f32a5887fa40'}]}\n"
     ]
    }
   ],
   "source": [
    "# get metadata on submissions for the music lab app after a certain submission ID\n",
    "\n",
    "formID = 284191\n",
    "submissionID = 23172339 # collect responses from after this submission ID. \n",
    "request_url = 'https://nettskjema.no/api/v2/forms/' + str(formID) + '/submissions?fromSubmissionId=' + str(submissionID)\n",
    "response = session.get(request_url)\n",
    "subIDs = json.loads(response.content.decode())\n",
    "print('Submissions since subID ' + str(submissionID) + ': ' + str(len(subIDs)))\n",
    "if len(subIDs)<5: # print error message or top responses \n",
    "    print(subIDs)\n",
    "else:\n",
    "    print(subIDs[0]) # print the most recent submission\n",
    "    print(subIDs[-1]) # print the earliest submission after the concert start (after response 23172339 which was collected '2022-09-23T19%3A30%3A00.000%2D0400' \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('..') # back t oparent (i.e. LIVElab folder)\n",
    "os.chdir('Concert_API')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time to collect 8236 attachments: 736.8054723739624\n"
     ]
    }
   ],
   "source": [
    "# pull in attachment files from the date of the concert and unpack them\n",
    "\n",
    "newSubs = 0 # count the submission sampled\n",
    "tic = time.time()\n",
    "for submis in subIDs: \n",
    "    # first find out the attachment file ID for this submission\n",
    "    # this will create a 3-hour time range for the motion, however it will include 30-mins after the concert start and ~1.5 hours after concert end. Future analysis should work to only select the real data.\n",
    "    if submis['createdDate'].startswith('2022-09-24T01') or submis['createdDate'].startswith('2022-09-24T02') or submis['createdDate'].startswith('2022-09-24T03'):\n",
    "        subID = str(submis['submissionId'])\n",
    "        # if there is an IDed attachment for this submission, get the file\n",
    "        for subm in submis['answers']:\n",
    "            if len(subm)>3: # cheat to pick out only submissions with attachments. might fail.\n",
    "                attID = str(subm['attachments'][0]['answerAttachmentId'])\n",
    "                request_url = 'https://nettskjema.no/api/v2/submissions/' + subID + '/attachments/' + attID\n",
    "                response = session.get(request_url)\n",
    "                newSubs += 1\n",
    "                att_dets = json.loads(response.content.decode())\n",
    "                # write the decoded attachment into a zip file\n",
    "                f=open('data.zip', 'wb')\n",
    "                f.write(base64.b64decode(att_dets['content']))\n",
    "                f.close()\n",
    "                # and then unzip that file, leaving a uniquely titled csv, I hope\n",
    "                with zipfile.ZipFile('data.zip', 'r') as zip_ref:\n",
    "                    if not os.path.exists(str(subID)):\n",
    "                        os.mkdir(str(subID))\n",
    "                        zip_ref.extractall('./'+str(subID)) # if not unique can use the unique submission IDs \n",
    "\n",
    "print('time to collect ' + str(newSubs) + ' attachments: ' + str(time.time() - tic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When I used a date range of 'if submis['createdDate'].startswith('2022-09-23') or submis['createdDate'].startswith('2022-09-24'): '\n",
    "I got:\n",
    "\n",
    "time to collect 8239 attachments: 765.3608708381653\n",
    "\n",
    "When I used the 3-hour time range, I got: if submis['createdDate'].startswith('2022-09-24T01') or submis['createdDate'].startswith('2022-09-24T02') or submis['createdDate'].startswith('2022-09-24T03'):\n",
    "\n",
    "time to collect 8236 attachments: 736.8054723739624"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('..') # back t oparent (i.e. LIVElab folder)\n",
    "os.mkdir('Concert_InstOrdData') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = os.listdir('Concert_API')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to put all the files inside the Installation Ordered Data folder for fastest sftp transfer\n",
    "foldlist = os.listdir('./Concert_InstOrdData/')\n",
    "\n",
    "for subid in folders:\n",
    "    if subid.startswith('23'):\n",
    "        filenames = os.listdir('./Concert_API/'+str(subid))\n",
    "        #print(filenames)\n",
    "        for fn in filenames:\n",
    "            if fn.endswith('.csv'):\n",
    "                # extract the installation ID \n",
    "                #subdets = fn.split('.') # worked before but now with the time, this was splitting at the ms level and the ms was being included with the installation ID\n",
    "                subdets = fn.split('_') # splits it into date, installation, type (dm.csv or gl.csv)\n",
    "                instid = subdets[1] # changed from Finn's because Pedro includes the date and time in the submission name.\n",
    "                # if the device doesn't have a folder, generate one\n",
    "                if instid not in foldlist:\n",
    "                    os.mkdir('./Concert_InstOrdData/' + instid)\n",
    "                    foldlist = os.listdir('./Concert_InstOrdData/')\n",
    "                    \n",
    "                sourcefile = './Concert_API/' + str(subid) + '/' + fn\n",
    "                targetfile = './Concert_InstOrdData/' + instid + '/'+str(subid) + '.' + fn\n",
    "                #print(targetfile)\n",
    "                shutil.copy2(sourcefile,targetfile)\n",
    "                \n",
    "#os.listdir('./InstOrdData/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 139 unique installation IDs from that 3 hour time range. This should include both the live and livestreaming audience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
